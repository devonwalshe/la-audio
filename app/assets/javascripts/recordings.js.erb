// Recordings JS
$( window ).load(function() {
  
  // Set up the global variables
  var segments = JSON.parse(gon.interview_segments);
  var interviewLength = gon.interview_length;
  var interview = document.getElementById("audioPlayer");
  
  // On time update, check which segment we're in and light up the bubble
  interview.ontimeupdate = function() {
    updateSegmentBubble();
  };

  // Get timecode from interview audio object
  function getTimeCode() {
  // Display the current position of the video in a <p> element with id="timecode"
    return interview.currentTime;
  }
  
  // Gets the current time, iterates through all the segments, and finds the relevant bubble, then lights it up
  function updateSegmentBubble() {
    currentTime = parseFloat(getTimeCode());
    // console.log(current_time.toFixed(1))
    
    // Iterate through segments to check if we are in a certain one
    for(i = 0; i < segments.length; i++){
      startTime = parseFloat(segments[i]["start_time"]);
      endTime = parseFloat(segments[i]["end_time"]);
      // console.log(startTime)
      // console.log(endTime)
      // console.log(currentTime)
      
      // Change segment bubbles colour if its in there
      if (currentTime >= startTime && currentTime <= endTime) {
        $("div#"+segments[i]["name"].toLowerCase().replace(/\s/g, "_")).addClass("bgorange").removeClass("bgblue");
      };
      
      if (currentTime <= startTime || currentTime >= endTime) {
        // console.log(segments[i])
        $("div#"+segments[i]["name"].toLowerCase().replace(/\s/g, "_")).addClass("bgblue").removeClass("bgorange");
      };
      
    }
  }
  
  // Draws lines where the segments are in the timeline below the audio player
  function drawSegmentLines(){
    
  }
  
  // Secondly check which segment the current time corresponds to
  function checkSegment(){
    current_time = interview.currentTime;
    
  }
  
})


  
